{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ***ML Algorithms***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression\n",
    "- logistic Regression\n",
    "- Neural Network\n",
    "- SVR\n",
    "- SVC\n",
    "- K-means\n",
    "- PCA\n",
    "- Decision Tree\n",
    "- Ensemble Regression\n",
    "- Ensemble Classifier\n",
    "- K Nearest Neighbors \n",
    "- NaiveBayes\n",
    "- LDA , QDA\n",
    "- Hierarchical Clusters\n",
    "- DbScan\n",
    "- NLP\n",
    "- Apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Linear Regression***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***linear_model***\n",
    "\n",
    "- LinearRegression\n",
    "- Lasso\n",
    "- Ridge\n",
    "- SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import median_absolute_error\n",
    "#----------------------------------------------------\n",
    "\n",
    "#load boston data\n",
    "\n",
    "BostonData = load_boston()\n",
    "\n",
    "#X Data\n",
    "X = BostonData.data\n",
    "\n",
    "#y Data\n",
    "y = BostonData.target\n",
    "\n",
    "#----------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Train Score is :  0.7391405291456344\n",
      "Linear Regression Test Score is :  0.7194574243020464\n",
      "Linear Regression Coef is :  [-1.52786535e-01  5.83438345e-02 -5.25729795e-02  1.74968794e+00\n",
      " -1.82628401e+01  3.19751214e+00 -1.82120263e-03 -1.79227933e+00\n",
      "  3.02644015e-01 -1.26348509e-02 -8.73594266e-01  1.05892477e-02\n",
      " -4.68960863e-01]\n",
      "Linear Regression intercept is :  40.16387456471213\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Splitting data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Applying Linear Regression Model \n",
    "\n",
    "Model = LinearRegression(fit_intercept=True, normalize=True,copy_X=True,n_jobs=-1)\n",
    "Model.fit(X_train, y_train)\n",
    "\n",
    "#Calculating Details\n",
    "print('Linear Regression Train Score is : ' , Model.score(X_train, y_train))\n",
    "print('Linear Regression Test Score is : ' , Model.score(X_test, y_test))\n",
    "print('Linear Regression Coef is : ' , Model.coef_)\n",
    "print('Linear Regression intercept is : ' , Model.intercept_)\n",
    "print('----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value for Linear Regression is :  [18.08835763 24.29913209 21.29334432 35.15238698 11.99842784]\n",
      "\n",
      "Mean Absolute Error Value is :  3.6397935186115555\n",
      "Mean Squared Error Value is :  27.59356237965675\n",
      "Median Squared Error Value is :  2.561978682194866\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Calculating Prediction\n",
    "y_pred = Model.predict(X_test)\n",
    "print('Predicted Value for Linear Regression is : ' , y_pred[:5])\n",
    "print()\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Absolute Error\n",
    "MAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Absolute Error Value is : ', MAEValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Squared Error\n",
    "MSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Squared Error Value is : ', MSEValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Median Squared Error\n",
    "MdSEValue = median_absolute_error(y_test, y_pred)\n",
    "print('Median Squared Error Value is : ', MdSEValue )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Lasso***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Train Score is :  0.6771305278565054\n",
      "Lasso Regression Test Score is :  0.6366169912303186\n",
      "Lasso Regression Coef is :  [-0.06749947  0.05901876 -0.0676006   0.         -0.          0.19519823\n",
      "  0.01995674 -0.95608401  0.23860719 -0.015207   -0.63201316  0.00811458\n",
      " -0.72751625]\n",
      "Lasso Regression intercept is :  45.650756491156976\n",
      "----------------------------------------------------\n",
      "Predicted Value for Lasso Regression is :  [18.48928473 21.78993926 20.91907098 32.27253839 15.30637937]\n",
      "Mean Absolute Error Value is :  4.0243272919298585\n",
      "Mean Squared Error Value is :  35.74156862019109\n",
      "Median Squared Error Value is :  2.5002961412025613\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import median_absolute_error\n",
    "#----------------------------------------------------\n",
    "\n",
    "#load boston data\n",
    "\n",
    "BostonData = load_boston()\n",
    "\n",
    "#X Data\n",
    "X = BostonData.data\n",
    "\n",
    "#y Data\n",
    "y = BostonData.target\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Splitting data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n",
    "\n",
    " #----------------------------------------------------\n",
    "#Applying Lasso Regression Model \n",
    "\n",
    "'''\n",
    "#sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=\n",
    "#                           False, copy_X=True, max_iter=1000, tol=0.0001,\n",
    "#                           warm_start=False, positive=False, random_state=None,selection='cyclic')\n",
    "'''\n",
    "\n",
    "LassoRegressionModel = Lasso(alpha=1.0,random_state=33,normalize=False)\n",
    "LassoRegressionModel.fit(X_train, y_train)\n",
    "\n",
    "#Calculating Details\n",
    "print('Lasso Regression Train Score is : ' , LassoRegressionModel.score(X_train, y_train))\n",
    "print('Lasso Regression Test Score is : ' , LassoRegressionModel.score(X_test, y_test))\n",
    "print('Lasso Regression Coef is : ' , LassoRegressionModel.coef_)\n",
    "print('Lasso Regression intercept is : ' , LassoRegressionModel.intercept_)\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "#Calculating Prediction\n",
    "y_pred = LassoRegressionModel.predict(X_test)\n",
    "print('Predicted Value for Lasso Regression is : ' , y_pred[:5])\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Absolute Error\n",
    "MAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Absolute Error Value is : ', MAEValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Squared Error\n",
    "MSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Squared Error Value is : ', MSEValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Median Squared Error\n",
    "MdSEValue = median_absolute_error(y_test, y_pred)\n",
    "print('Median Squared Error Value is : ', MdSEValue )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Ridge***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Train Score is :  0.7359190514377463\n",
      "Ridge Regression Test Score is :  0.716858250738577\n",
      "Ridge Regression Coef is :  [-0.14428942  0.05972008 -0.09000631  1.56026811 -9.06085979  3.1984024\n",
      " -0.00931524 -1.65498927  0.27826889 -0.01339655 -0.77566368  0.01074529\n",
      " -0.48600773]\n",
      "Ridge Regression intercept is :  34.33744293090315\n",
      "----------------------------------------------------\n",
      "Predicted Value for Ridge Regression is :  [18.05200951 23.55480134 21.11622888 34.81904322 12.37543491 32.16690905\n",
      " 19.91533263 24.57458378 30.49754442 22.87886074]\n",
      "Mean Absolute Error Value is :  3.6103589525512207\n",
      "Mean Squared Error Value is :  27.849211482758896\n",
      "Median Squared Error Value is :  2.1934805378612214\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "#----------------------------------------------------\n",
    "\n",
    "#load boston data\n",
    "BostonData = load_boston()\n",
    "\n",
    "#X Data\n",
    "X = BostonData.data\n",
    "\n",
    "#y Data\n",
    "y = BostonData.target\n",
    "#----------------------------------------------------\n",
    "#Splitting data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n",
    "#----------------------------------------------------\n",
    "#Applying Ridge Regression Model \n",
    "\n",
    "'''\n",
    "#sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False,\n",
    "#                           copy_X=True, max_iter=None, tol=0.001, solver='auto',\n",
    "#                           random_state=None)\n",
    "'''\n",
    "\n",
    "RidgeRegressionModel = Ridge(alpha=1.0,random_state=33)\n",
    "RidgeRegressionModel.fit(X_train, y_train)\n",
    "\n",
    "#Calculating Details\n",
    "print('Ridge Regression Train Score is : ' , RidgeRegressionModel.score(X_train, y_train))\n",
    "print('Ridge Regression Test Score is : ' , RidgeRegressionModel.score(X_test, y_test))\n",
    "print('Ridge Regression Coef is : ' , RidgeRegressionModel.coef_)\n",
    "print('Ridge Regression intercept is : ' , RidgeRegressionModel.intercept_)\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "#Calculating Prediction\n",
    "y_pred = RidgeRegressionModel.predict(X_test)\n",
    "print('Predicted Value for Ridge Regression is : ' , y_pred[:10])\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Absolute Error\n",
    "MAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Absolute Error Value is : ', MAEValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Squared Error\n",
    "MSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Squared Error Value is : ', MSEValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Median Squared Error\n",
    "MdSEValue = median_absolute_error(y_test, y_pred)\n",
    "print('Median Squared Error Value is : ', MdSEValue )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***SGDRegressor***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Regression Train Score is :  -0.8533872766675272\n",
      "SGD Regression Test Score is :  -0.3885413640778155\n",
      "SGD Regression Coef is :  [-0.09506343  0.04161878 -0.08845053  0.01268795  0.00652309  0.17934089\n",
      "  0.12647817 -0.00060846  0.03782581 -0.01089733  0.10434043  0.0783665\n",
      " -0.36668272]\n",
      "SGD Regression intercept is :  [0.03929182]\n",
      "----------------------------------------------------\n",
      "Predicted Value for SGD Regression is :  [33.37297431 35.17097853 28.11985931 35.54699757 -2.16403117 36.82772943\n",
      " 29.09476909 33.27746677 34.03931331 32.54193396]\n",
      "Mean Absolute Error Value is :  10.535509086592084\n",
      "Mean Squared Error Value is :  136.57393232058487\n",
      "Median Squared Error Value is :  11.244045334095386\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "#----------------------------------------------------\n",
    "\n",
    "#load boston data\n",
    "\n",
    "BostonData = load_boston()\n",
    "\n",
    "#X Data\n",
    "X = BostonData.data\n",
    "#y Data\n",
    "y = BostonData.target\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Splitting data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Applying SGDRegressor Model \n",
    "\n",
    "'''\n",
    "#sklearn.linear_model.SGDRegressor(loss='squared_loss’, penalty=’l2’, alpha=0.0001,\n",
    "#                                  l1_ratio=0.15, fit_intercept=True, max_iter=None,\n",
    "#                                  tol=None, shuffle=True, verbose=0, epsilon=0.1,\n",
    "#                                  random_state=None, learning_rate='invscaling’,\n",
    "#                                  eta0=0.01, power_t=0.25, early_stopping=False,\n",
    "#                                  validation_fraction=0.1, n_iter_no_change=5,\n",
    "#                                  warm_start=False, average=False, n_iter=None)\n",
    "'''\n",
    "\n",
    "SGDRegressionModel = SGDRegressor(alpha=0.1,random_state=33,penalty='l2',loss = 'huber')\n",
    "SGDRegressionModel.fit(X_train, y_train)\n",
    "\n",
    "#Calculating Details\n",
    "print('SGD Regression Train Score is : ' , SGDRegressionModel.score(X_train, y_train))\n",
    "print('SGD Regression Test Score is : ' , SGDRegressionModel.score(X_test, y_test))\n",
    "print('SGD Regression Coef is : ' , SGDRegressionModel.coef_)\n",
    "print('SGD Regression intercept is : ' , SGDRegressionModel.intercept_)\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "#Calculating Prediction\n",
    "y_pred = SGDRegressionModel.predict(X_test)\n",
    "print('Predicted Value for SGD Regression is : ' , y_pred[:10])\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Absolute Error\n",
    "MAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Absolute Error Value is : ', MAEValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Squared Error\n",
    "MSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Squared Error Value is : ', MSEValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Median Squared Error\n",
    "MdSEValue = median_absolute_error(y_test, y_pred)\n",
    "print('Median Squared Error Value is : ', MdSEValue )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Logistic Regression***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- linear_model.LogistcRegression\n",
    "- linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LogistcRegression***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tol            مقدار الخطأ المسموح به\n",
    "- C              مقلوب قيمة التنعيم\n",
    "- random state   لتحديد الهيكلة المستخدمة في عشوائية البيانات\n",
    "- max iter       العدد الاقي للمحاولات\n",
    "- n_jobs         لتحديد مدى سرعة العملية\n",
    "- solver         معادلة التصنيف\n",
    "- small data= 'liblinear',    big data= 'sag','saga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features = \n",
      " [ True False  True False False False False  True False False False False\n",
      " False  True False False False False False False  True False  True  True\n",
      " False False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 20)) \n",
    "sel.fit(X,y)\n",
    "selected_features = sel.transform(X)\n",
    "\n",
    "sfeatures = sel.get_support()\n",
    "print('Selected features = \\n' , sfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(selected_features, y, test_size = 0.2)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train , y_train)\n",
    "result= logreg.predict(x_test)\n",
    "print(accuracy_score(y_test , result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix \n",
      " [[43  5]\n",
      " [ 3 63]]\n"
     ]
    }
   ],
   "source": [
    "conf = confusion_matrix(y_test , result)\n",
    "print('confusion matrix \\n',  conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionModel Train Score is :  0.9606299212598425\n",
      "LogisticRegressionModel Test Score is :  0.9680851063829787\n",
      "LogisticRegressionModel Classes are :  [0 1]\n",
      "LogisticRegressionModel No. of iteratios is :  [91]\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#----------------------------------------------------\n",
    "\n",
    "#load breast cancer data\n",
    "\n",
    "BreastData = load_breast_cancer()\n",
    "\n",
    "#X Data\n",
    "X = BreastData.data\n",
    "\n",
    "#y Data\n",
    "y = BreastData.target\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Splitting data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n",
    "\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Applying LogisticRegression Model \n",
    "\n",
    "'''\n",
    "#linear_model.LogisticRegression(penalty='l2’,dual=False,tol=0.0001,C=1.0,fit_intercept=True,intercept_scaling=1,\n",
    "#                                class_weight=None,random_state=None,solver='warn’,max_iter=100,\n",
    "#                                multi_class='warn’, verbose=0,warm_start=False, n_jobs=None)\n",
    "'''\n",
    "\n",
    "LogisticRegressionModel = LogisticRegression(penalty='l1',solver='liblinear',C=1.0,random_state=33, max_iter=10000)\n",
    "LogisticRegressionModel.fit(X_train, y_train)\n",
    "\n",
    "#Calculating Details\n",
    "print('LogisticRegressionModel Train Score is : ' , LogisticRegressionModel.score(X_train, y_train))\n",
    "print('LogisticRegressionModel Test Score is : ' , LogisticRegressionModel.score(X_test, y_test))\n",
    "print('LogisticRegressionModel Classes are : ' , LogisticRegressionModel.classes_)\n",
    "print('LogisticRegressionModel No. of iteratios is : ' , LogisticRegressionModel.n_iter_)\n",
    "print('----------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value for LogisticRegressionModel is :  [0 0 1 0 1 1 1 1 0 1]\n",
      "Prediction Probabilities Value for LogisticRegressionModel is : \n",
      " [[9.92356891e-01 7.64310921e-03]\n",
      " [9.99999996e-01 4.06213706e-09]\n",
      " [2.18923277e-02 9.78107672e-01]\n",
      " [1.00000000e+00 1.67907096e-10]\n",
      " [3.05823485e-01 6.94176515e-01]\n",
      " [9.79896474e-02 9.02010353e-01]\n",
      " [1.83458858e-04 9.99816541e-01]\n",
      " [7.21203683e-02 9.27879632e-01]\n",
      " [9.97731306e-01 2.26869377e-03]\n",
      " [1.04601572e-03 9.98953984e-01]]\n",
      "----------------------------------------------------\n",
      "Confusion Matrix is : \n",
      " [[ 65   3]\n",
      " [  3 117]]\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Calculating Prediction\n",
    "y_pred = LogisticRegressionModel.predict(X_test)\n",
    "y_pred_prob = LogisticRegressionModel.predict_proba(X_test)\n",
    "print('Predicted Value for LogisticRegressionModel is : ' , y_pred[:10])\n",
    "print('Prediction Probabilities Value for LogisticRegressionModel is : \\n' , y_pred_prob[:10])\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "#Calculating Confusion Matrix\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix is : \\n', CM)\n",
    "print('----------------------------------------------------')\n",
    "# drawing confusion matrix\n",
    "sns.heatmap(CM, center = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is :  0.9680851063829787\n",
      "F1 Score is :  0.9680851063829787\n",
      "Recall Score is :  0.9680851063829787\n",
      "Precision Score is :  0.9680851063829787\n",
      "Precision Recall Score is :  (0.9680851063829787, 0.9680851063829787, 0.9680851063829787, None)\n",
      "Precision Value is :  [0.63829787 0.975      1.        ]\n",
      "Recall Value is :  [1.    0.975 0.   ]\n",
      "Thresholds Value is :  [0 1]\n",
      "Classification Report is :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        68\n",
      "           1       0.97      0.97      0.97       120\n",
      "\n",
      "    accuracy                           0.97       188\n",
      "   macro avg       0.97      0.97      0.97       188\n",
      "weighted avg       0.97      0.97      0.97       188\n",
      "\n",
      "AUC Value  :  0.9654411764705882\n",
      "fpr Value  :  [0.         0.04411765 1.        ]\n",
      "tpr Value  :  [0.    0.975 1.   ]\n",
      "thresholds Value  :  [2 1 0]\n",
      "ROCAUC Score :  0.9654411764705882\n",
      "Zero One Loss Value :  6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))\n",
    "AccScore = accuracy_score(y_test, y_pred, normalize=True)\n",
    "print('Accuracy Score is : ', AccScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)\n",
    "# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "\n",
    "F1Score = f1_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('F1 Score is : ', F1Score)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Recall Score : (Sensitivity) (TP / float(TP + FN))   1 / 1+2  \n",
    "# recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "\n",
    "RecallScore = recall_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('Recall Score is : ', RecallScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  \n",
    "# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)\n",
    "\n",
    "PrecisionScore = precision_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('Precision Score is : ', PrecisionScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Precision recall Score :  \n",
    "#metrics.precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1, average=\n",
    "#                                        None, warn_for = ('precision’,’recall’, ’f-score’), sample_weight=None)\n",
    "\n",
    "PrecisionRecallScore = precision_recall_fscore_support(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('Precision Recall Score is : ', PrecisionRecallScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Precision recall Curve :  \n",
    "# precision_recall_curve(y_true, probas_pred, pos_label=None, sample_weight=None)\n",
    "\n",
    "PrecisionValue, RecallValue, ThresholdsValue = precision_recall_curve(y_test,y_pred)\n",
    "print('Precision Value is : ', PrecisionValue)\n",
    "print('Recall Value is : ', RecallValue)\n",
    "print('Thresholds Value is : ', ThresholdsValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating classification Report :  \n",
    "#classification_report(y_true, y_pred, labels=None, target_names=None,sample_weight=None, digits=2, output_dict=False)\n",
    "\n",
    "ClassificationReport = classification_report(y_test,y_pred)\n",
    "print('Classification Report is : ', ClassificationReport )\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Area Under the Curve :  \n",
    "\n",
    "fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)\n",
    "AUCValue = auc(fprValue2, tprValue2)\n",
    "print('AUC Value  : ', AUCValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Receiver Operating Characteristic :  \n",
    "#roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)\n",
    "\n",
    "fprValue, tprValue, thresholdsValue = roc_curve(y_test,y_pred)\n",
    "print('fpr Value  : ', fprValue)\n",
    "print('tpr Value  : ', tprValue)\n",
    "print('thresholds Value  : ', thresholdsValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating ROC AUC Score:  \n",
    "#roc_auc_score(y_true, y_score, average=’macro’, sample_weight=None,max_fpr=None)\n",
    "\n",
    "ROCAUCScore = roc_auc_score(y_test,y_pred, average='micro') #it can be : macro,weighted,samples\n",
    "print('ROCAUC Score : ', ROCAUCScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Zero One Loss:  \n",
    "#zero_one_loss(y_true, y_pred, normalize = True, sample_weight = None)\n",
    "\n",
    "ZeroOneLossValue = zero_one_loss(y_test,y_pred,normalize=False) \n",
    "print('Zero One Loss Value : ', ZeroOneLossValue )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E LogisticRegression(C=0.5, max_iter=1000, random_state=10, tol=0.01)\n",
      "score =  0.9666666666666667\n",
      "No of iterations =  [85]\n",
      "Classes =  [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=10, solver='lbfgs' , max_iter= 1000 , C = 0.5 , tol = 0.01)\n",
    "#clf = LogisticRegression(random_state=10, solver='liblinear')\n",
    "#clf = LogisticRegression(random_state=10, solver='saga')\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :])\n",
    "print('E',clf)\n",
    "score = clf.score(X, y)\n",
    "\n",
    "print('score = ' , score)\n",
    "print('No of iterations = ' , clf.n_iter_)\n",
    "print('Classes = ' , clf.classes_)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SGDClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifierModel Train Score is :  0.6220472440944882\n",
      "SGDClassifierModel Test Score is :  0.6382978723404256\n",
      "SGDClassifierModel loss function is :  <sklearn.linear_model._sgd_fast.SquaredLoss object at 0x000001395D6FFB50>\n",
      "SGDClassifierModel No. of iteratios is :  77\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#----------------------------------------------------\n",
    "\n",
    "#load breast cancer data\n",
    "\n",
    "BreastData = load_breast_cancer()\n",
    "\n",
    "#X Data\n",
    "X = BreastData.data\n",
    "\n",
    "#y Data\n",
    "y = BreastData.target\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Splitting data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n",
    "\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Applying SGDClassifier Model \n",
    "\n",
    "'''\n",
    "#sklearn.linear_model.SGDClassifier(loss='hinge’, penalty=’l2’, alpha=0.0001,l1_ratio=0.15, fit_intercept=True,\n",
    "#                                   max_iter=None,tol=None, shuffle=True, verbose=0, epsilon=0.1,n_jobs=None,\n",
    "#                                   random_state=None, learning_rate='optimal’, eta0=0.0, power_t=0.5,\n",
    "#                                   early_stopping=False, validation_fraction=0.1,n_iter_no_change=5,\n",
    "#                                   class_weight=None,warm_start=False, average=False, n_iter=None)\n",
    "'''\n",
    "\n",
    "SGDClassifierModel = SGDClassifier(penalty='l2',loss='squared_loss',learning_rate='optimal',random_state=33)\n",
    "SGDClassifierModel.fit(X_train, y_train)\n",
    "\n",
    "#Calculating Details\n",
    "print('SGDClassifierModel Train Score is : ' , SGDClassifierModel.score(X_train, y_train))\n",
    "print('SGDClassifierModel Test Score is : ' , SGDClassifierModel.score(X_test, y_test))\n",
    "print('SGDClassifierModel loss function is : ' , SGDClassifierModel.loss_function_)\n",
    "print('SGDClassifierModel No. of iteratios is : ' , SGDClassifierModel.n_iter_)\n",
    "print('----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value for SGDClassifierModel is :  [1 1 1 1 1 1 1 1 1 1]\n",
      "Confusion Matrix is : \n",
      " [[  0  68]\n",
      " [  0 120]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is :  120\n",
      "F1 Score is :  0.6382978723404256\n",
      "Precision Recall Score is :  (0.6382978723404256, 0.6382978723404256, 0.6382978723404256, None)\n",
      "Precision Score is :  0.6382978723404256\n",
      "Recall Score is :  0.6382978723404256\n",
      "Thresholds Value is :  [1]\n",
      "Classification Report is :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.64      1.00      0.78       120\n",
      "\n",
      "    accuracy                           0.64       188\n",
      "   macro avg       0.32      0.50      0.39       188\n",
      "weighted avg       0.41      0.64      0.50       188\n",
      "\n",
      "AUC Value  :  0.5\n",
      "Zero One Loss Value :  68\n",
      "ROCAUC Score :  0.5\n",
      "fpr Value  :  [0. 1.]\n",
      "tpr Value  :  [0. 1.]\n",
      "thresholds Value  :  [2 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\holol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Calculating Prediction\n",
    "y_pred = SGDClassifierModel.predict(X_test)\n",
    "print('Predicted Value for SGDClassifierModel is : ' , y_pred[:10])\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Confusion Matrix\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix is : \\n', CM)\n",
    "\n",
    "# drawing confusion matrix\n",
    "sns.heatmap(CM, center = True)\n",
    "plt.show()\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))\n",
    "AccScore = accuracy_score(y_test, y_pred, normalize=False)\n",
    "print('Accuracy Score is : ', AccScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)\n",
    "# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "\n",
    "F1Score = f1_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('F1 Score is : ', F1Score)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Precision recall Score :  \n",
    "#metrics.precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1, average=\n",
    "#                                        None, warn_for = ('precision’,’recall’, ’f-score’), sample_weight=None)\n",
    "\n",
    "PrecisionRecallScore = precision_recall_fscore_support(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('Precision Recall Score is : ', PrecisionRecallScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  \n",
    "# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)\n",
    "\n",
    "PrecisionScore = precision_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('Precision Score is : ', PrecisionScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Recall Score : (Sensitivity) (TP / float(TP + FN))   1 / 1+2  \n",
    "# recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "\n",
    "RecallScore = recall_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('Recall Score is : ', RecallScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Precision recall Curve :  \n",
    "# precision_recall_curve(y_true, probas_pred, pos_label=None, sample_weight=None)\n",
    "\n",
    "PrecisionValue, RecallValue, ThresholdsValue = precision_recall_curve(y_test,y_pred)\n",
    "#print('Precision Value is : ', PrecisionValue)\n",
    "#print('Recall Value is : ', RecallValue)\n",
    "print('Thresholds Value is : ', ThresholdsValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating classification Report :  \n",
    "#classification_report(y_true, y_pred, labels=None, target_names=None,sample_weight=None, digits=2, output_dict=False)\n",
    "\n",
    "ClassificationReport = classification_report(y_test,y_pred)\n",
    "print('Classification Report is : ', ClassificationReport )\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Area Under the Curve :  \n",
    "\n",
    "fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)\n",
    "AUCValue = auc(fprValue2, tprValue2)\n",
    "print('AUC Value  : ', AUCValue)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Zero One Loss:  \n",
    "#zero_one_loss(y_true, y_pred, normalize = True, sample_weight = None)\n",
    "\n",
    "ZeroOneLossValue = zero_one_loss(y_test,y_pred,normalize=False) \n",
    "print('Zero One Loss Value : ', ZeroOneLossValue )\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating ROC AUC Score:  \n",
    "#roc_auc_score(y_true, y_score, average=’macro’, sample_weight=None,max_fpr=None)\n",
    "\n",
    "ROCAUCScore = roc_auc_score(y_test,y_pred, average='micro') #it can be : macro,weighted,samples\n",
    "print('ROCAUC Score : ', ROCAUCScore)\n",
    "\n",
    "#----------------------------------------------------\n",
    "#Calculating Receiver Operating Characteristic :  \n",
    "#roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)\n",
    "\n",
    "fprValue, tprValue, thresholdsValue = roc_curve(y_test,y_pred)\n",
    "print('fpr Value  : ', fprValue)\n",
    "print('tpr Value  : ', tprValue)\n",
    "print('thresholds Value  : ', thresholdsValue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e47254bb17cc6746e905ae014bc04f6681234d7e0366d8541590b18c10f99a04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
